import os
from os import system, popen
from unidecode import unidecode
import unicodedata
from googletrans import Translator
import unicodedata, re
from urllib.request import urlopen, urlretrieve
from urllib.parse import quote
from bs4 import BeautifulSoup
import simpleaudio as sa
from pynput.keyboard import Key, Listener, KeyCode
import requests
import vlc
from mutagen.mp3 import MP3
from time import sleep
import threading
import ssl
import re
from prettytable import PrettyTable
import pyphen
dic = pyphen.Pyphen(lang='ru')

NOTIFY_ID = 62231
PLAY_ID = 622331
GRAMM_ID = 162231
PAGE_ID = 362231
DICT_ID = 562231
EXAM_ID = 762231
MAX_ROW_LENGTH = 100
EXAM_PER_PAGE = 10

def remove_accents(input_str):
	nfkd_form = unicodedata.normalize('NFKD', input_str)
	return u"".join([c for c in nfkd_form if not unicodedata.combining(c)])

def rid_comma(out):
	rows = out.split('\n')
	mod = []
	for row in rows:
		if row.find(',') == -1:
			mod.append(row)
		else:
			lst = 0
			pos = row.find(',')
			line = '\t\t\t\t'
			while pos>-1:
				prev = row[lst:pos+1]
				end = row.find('\t', pos)
				blk = row[pos+1:end]
				line += blk + '\t'
				lst = end
				pos = row.find(',', lst)
			prev += row[lst:-1]
			mod.append(prev)
			mod.append(line)
	s = ''
	for row in mod:
		s += row + '\n'

	return s

def full_count(s):
	num = 0
	for i in range(len(s)):
		if unicodedata.east_asian_width(s[i]) in ['W', 'F']:
			num += 1
		if unicodedata.east_asian_width(s[i]) in ['A']:
			num += 0.15
	return len(s) + int(num)

def split_row(s):
	if len(s) > MAX_ROW_LENGTH:
		i = 0
		split = ''
		for c in s:
			split += c
			i += full_count(c)
			if i > MAX_ROW_LENGTH:
				split += '\n  '
				i = 0
		return split
	else:
		return s

def adjust_tab(out, name='', tab_width=2):
	x = PrettyTable()
	item = [_.split('\t') for _ in out.split('\n')]
	for i, row in enumerate(item):
		if i:
			x.add_row(row[:-1])
		else:
			if name:
				row[0] = name
			x.field_names = row[:-1]
	print(x)
	# return x.get_string()

	# item = [x.split('\t') for x in out.split('\n')]
	rc, lc = len(item), len(item[0])-1
	adj = ['  ' for _ in item]
	adj[0] = 'ÔÜú '
	for j in range(0, lc):
		lens = [full_count(item[i][j]) for i in range(rc)]
		for i in range(rc):
			adj[i] += item[i][j] + ' '*(max(lens) - full_count(item[i][j]) + tab_width)
	s = ''
	for row in adj:
		s += row + '\n'

	return s[:-1]

system('xdotool key "Escape"')
sound_path = "/tmp/Russian"
if not os.path.exists(sound_path):
	os.mkdir(sound_path)
tmp = popen('xsel').read()
tmp = tmp.replace("`",'').strip()
if tmp.find(' ')>-1:
	tmp = tmp[0:tmp.find(' ')]
if tmp.find('\n')>-1:
	tmp = tmp[0:tmp.find('\n')]
tmp = "".join([x.lower() for x in tmp if x.isalpha()])
tmp = tmp.strip()
phen = dic.inserted(tmp)
phen = phen.lower().replace("'","‚Äô").strip().replace(" ","-")
word = remove_accents(tmp)
pron = unidecode(tmp)
pron = pron.lower().replace("'","‚Äô").strip().replace(" ","-")
phen_pron = unidecode(phen)
phen_pron = phen_pron.lower().replace("'","‚Äô").strip().replace(" ","-")
system("dunstify -r %d 'ÔÜå %s [%s]'"%(NOTIFY_ID, word, pron))

translator = Translator()
try:
	a = translator.translate(tmp)
	trans = a.text
except:
	system("dunstify -r %d -u low '–ü–µ—Ä–µ–≤–æ–¥–∏–º–æ–µ —Å–ª–æ–≤–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\nNo translatable word dectected.'"%NOTIFY_ID)
else:
	trans = trans.lower().replace("'","‚Äô")
	if word == trans:
		# system("dunstify -r %d -u low '–†—É—Å—Å–∫–æ–µ —Å–ª–æ–≤–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\n%s - No Russian word dectected.'"%(NOTIFY_ID, tmp))
		system("python ~/.i3/get_jukuu.py %s"%word)
	else:
		url = "https://www.igimu.com/index.php?q=%s"%(quote(word))
		print("https://www.igimu.com/index.php?q=%s"%word)
		context = ssl._create_unverified_context()
		res = urlopen(url, context=context)
		soup = BeautifulSoup(res, "html.parser")
		mean = soup.findAll('p', class_='exp')
		for one in mean:
			for i in one.select("br"):
				i.replace_with(',')
		key = soup.findAll('h2', class_='keyword')
		if mean[0].text == 'ÊöÇÊó†Èáä‰πâ.':
			orgn, pron_orgn, expl = key[-1].text, unidecode(key[-1].text), mean[-1].text
		else:
			orgn, pron_orgn, expl = key[0].text, unidecode(key[0].text), mean[0].text
		orgn = orgn.replace('–µ"', '—ë').replace("'","‚Äô")
		pron_orgn = unidecode(orgn)
		pron_orgn = pron_orgn.lower().replace("'","‚Äô").strip().replace(" ","-")
		phen_orgn = dic.inserted(orgn)
		phen_orgn = phen_orgn.lower().replace("'","‚Äô").strip().replace(" ","-")
		phen_pron_orgn = unidecode(phen_orgn)
		phen_pron_orgn = phen_pron_orgn.lower().replace("'","‚Äô").strip().replace(" ","-")
		expl = expl.replace("„ÄêËàπËà∂„Äë","").replace("„ÄêËà™Á©∫„Äë","").replace("'","‚Äô")
		expl = re.sub(' +', ' ', expl)
		item = expl.split(',')
		expl = ''
		for one in item:
			if expl.find(one)==-1:
				expl += one + ', '
		if expl:
			expl = expl[:-2]
		print(expl)
		expl = split_row(expl)
		system("dunstify -t 0 -r %d 'ÔÅ¨ %s [%s] %s' '  %s.'"%(DICT_ID, orgn, pron_orgn, trans, expl))

		page = soup.findAll('div', class_='subExp view')
		sel = ''
		for each in page:
			for i in each.select("br"):
				i.replace_with('; ')
			if len(sel)<len(each.text):
				sel = each.text
		sel = "".join([s for s in sel.strip().splitlines(True) if s.strip()])
		sel = re.sub(' +', ' ', sel)
		sel = sel.replace("'","‚Äô")
		more = sel[0:sel.find('\n')].strip()
		more = more.replace('–µ"', '—ë').replace("'","‚Äô")
		pron_more = unidecode(orgn)
		pron_more = pron_more.lower().replace("'","‚Äô").strip().replace(" ","-")
		phen_more = dic.inserted(more)
		phen_more = phen_orgn.lower().replace("'","‚Äô").strip().replace(" ","-")
		phen_pron_more = unidecode(phen_more)
		phen_pron_more = phen_pron_more.lower().replace("'","‚Äô").strip().replace(" ","-")

		sel = sel[sel.find('\n'):-1].strip().replace("\n"," ").replace(").",")").replace("~","").replace("'","‚Äô")
		print(sel)
		sel = split_row(sel)

		exam_ru = soup.findAll('p', class_='exam-a')
		rus, chn = [], []
		for one in exam_ru:
			rus.append(split_row(re.sub(' +', ' ', one.text).replace('\n', '').replace('\r', '').replace("'","‚Äô").strip()))
		exam_cn = soup.findAll('p', class_='exam-b')
		for one in exam_cn:
			chn.append(split_row(re.sub(' +', ' ', one.text).replace('\n', '').replace('\r', '').replace("'","‚Äô").strip()))
		for i in range(EXAM_PER_PAGE):
			if i < len(rus):
				system("dunstify -t 0 -r %d -u low 'ÔÜå %s' '  %s'"%(EXAM_ID + i, rus[i], chn[i]))
		system("dunstify -t 0 -r %d -u low 'ÔÅ§ ex. 1-%d / %d' '‚Ñ¢üñ≠ Pronunciation   ‚Üë‚Üì Example   ‚Üê‚Üí Declension    ‚åò+‚áß+p Online   ‚Ü≤ Dictionary'"%(EXAM_ID + EXAM_PER_PAGE, min(len(rus), EXAM_PER_PAGE), len(rus)))

		grammar = soup.findAll('table')
		title = soup.find('div', class_='grammardiv')
		if title:
			h3 = title.findAll('h3')
		declist = []
		for i, table in enumerate(grammar):
			rows = table.findAll("tr")
			out = ''
			for row in rows:
				items = row.findAll("th")
				for item in items:
					one = item.text
					out += one.replace('–µ"', '—ë').replace("'","‚Äô") + '\t'
				decl = row.findAll("td")
				for item in decl:
					one = item.text
					out += one.replace('–µ"', '—ë').replace("'","‚Äô").replace(', ', '/').replace('//', '/') + '\t'
				out += '\n'
			# out = rid_comma(out)
			if title and h3 and i<len(h3):
				out = adjust_tab(out[0:len(out)-1], h3[i].text)
			else:
				out = adjust_tab(out[0:len(out)-1], orgn)
			if not out in declist:
				declist.append(out)
		if declist:
			ind = 0
			system("dunstify -t 0 -r %d 'ÔÜå %s [%s] %s'"%(NOTIFY_ID, word, pron, trans))
			system("dunstify -t 0 -r %d '%s' 'ÔÅ§ pp. %d / %d'"%(GRAMM_ID, declist[ind], ind+1, len(declist)))

		file = "%s/%s.mp3"%(sound_path,word)
		if not os.path.exists(file):
			read = soup.find('a', class_='speaker')
			if read:
				system("dunstify -t 0 -r %d '‚èØ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è...'"%PLAY_ID)
				urlretrieve(read['data-url'], file)
				system("dunstify -t 0 -r %d -u low '‚èØ %s [%s] %s'"%(PLAY_ID, phen_orgn, phen_pron_orgn, trans))
				audio = MP3(file)
				value = audio.info.length
			else:
				system("dunstify -t 0 -r %d 'ÔÜå %s [%s] %s'"%(NOTIFY_ID, phen, phen_pron, trans))
				system("dunstify -t 0 -r %d -u low '‚èØ –ù–µ—Ç –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è.'"%PLAY_ID)
		else:
			system("dunstify -t 0 -r %d -u low '‚èØ %s [%s] %s'"%(PLAY_ID, phen_orgn, phen_pron_orgn, trans))
			audio = MP3(file)
			value = audio.info.length

		def pronunciate(anime=True):
			global play_blk
			if not play_blk:
				play_blk = 1
				media_player = vlc.MediaPlayer()
				media = vlc.Media(file)
				media_player.set_media(media)
				media_player.play()
				if anime:
					yin = phen_pron_orgn.split('-')
					prev = ''
					for i in range(len(yin)):
						if i:
							prev += '-' + yin[i]
						else:
							prev += yin[i]
						jd = prev + '-'*(len(phen_pron_orgn) - len(prev))
						system("dunstify -t 0 -r %d -u critical '‚èØ %s [%s] %s'"%(PLAY_ID, phen_orgn, jd, trans))
						sleep(value/len(yin))
				else:
					system("dunstify -t 0 -r %d -u critical '‚èØ %s [%s] %s'"%(PLAY_ID, phen_orgn, phen_pron_orgn, trans))
					sleep(value)
				system("dunstify -t 0 -r %d -u low '‚èØ %s [%s] %s'"%(PLAY_ID, phen_orgn, phen_pron_orgn, trans))
				play_blk = 0

		def browse():
			system("google-chrome-stable  --new-window %s"%url)

		def on_press(key):
			COMBINATIONS = [
				{Key.shift, Key.cmd_l, KeyCode(char='p')},
    			{Key.shift, Key.cmd_l, KeyCode(char='P')}
			]
			global ind, offset, dict_flag, orgn, pron_orgn, expl, word, pron, trans
			# print('{0} release'.format(key))
			if any([key in COMBO for COMBO in COMBINATIONS]):
				current.add(key)
				if any(all(k in current for k in COMBO) for COMBO in COMBINATIONS):
					threading.Thread(target=browse).start()
			if key in [Key.space, Key.ctrl, Key.ctrl_r, Key.caps_lock] and os.path.exists(file):
				threading.Thread(target=pronunciate).start()
			if key in [Key.enter, Key.shift, Key.shift_r]:
				if dict_flag:
					system("dunstify -t 0 -r %d 'ÔÅ¨ %s [%s] %s' '  %s.'"%(DICT_ID, orgn, pron_orgn, trans, expl))
				else:
					system("dunstify -t 0 -r %d 'ÔÅ¨ %s [%s] %s' '  %s'"%(DICT_ID, more, pron_more, trans, sel))
				dict_flag = 1 - dict_flag
			if key in [Key.right, Key.end] and declist:
				ind += 1
				if ind >= len(declist):
					ind = 0
				system("dunstify -t 0 -r %d '%s' 'ÔÅ§ pp. %d / %d'"%(GRAMM_ID, declist[ind], ind+1, len(declist)))
			if declist and key in [Key.left, key.home]:
				ind -= 1
				if ind < 0:
					ind = len(declist) - 1
				system("dunstify -t 0 -r %d '%s' 'ÔÅ§ pp. %d / %d'"%(GRAMM_ID, declist[ind], ind+1, len(declist)))
			if key in [Key.down, Key.page_down]:
				offset += EXAM_PER_PAGE
				if offset >= len(rus):
					offset = 0
				start, end = offset + 1, offset + EXAM_PER_PAGE
				for i in range(EXAM_PER_PAGE):
					ch = i + offset
					if ch < len(rus):
						system("dunstify -t 0 -r %d -u low 'ÔÜå %s' '  %s'"%(EXAM_ID + i, rus[ch], chn[ch]))
					else:
						system("dunstify -C %d"%(EXAM_ID + i))
						end = len(rus)
				system("dunstify -t 0 -r %d -u low 'ÔÅ§ ex. %d-%d / %d' '‚Ñ¢üñ≠ Pronunciation   ‚Üë‚Üì Example   ‚Üê‚Üí Declension    ‚åò+‚áß+p Online   ‚Ü≤ Dictionary'"%(EXAM_ID + EXAM_PER_PAGE, start, end, len(rus)))
			if key in [Key.up, Key.page_up]:
				offset -= EXAM_PER_PAGE
				if offset < 0:
					offset = EXAM_PER_PAGE * int(len(rus)/EXAM_PER_PAGE)
					if len(rus) % EXAM_PER_PAGE==0:
						offset -= EXAM_PER_PAGE
				start, end = offset + 1, offset + EXAM_PER_PAGE
				for i in range(EXAM_PER_PAGE):
					ch = i + offset
					if ch < len(rus):
						system("dunstify -t 0 -r %d -u low 'ÔÜå %s' '  %s'"%(EXAM_ID + i, rus[ch], chn[ch]))
					else:
						system("dunstify -C %d"%(EXAM_ID + i))
						end = len(rus)
				system("dunstify -t 0 -r %d -u low 'ÔÅ§ ex. %d-%d / %d' '‚Ñ¢üñ≠ Pronunciation   ‚Üë‚Üì Example   ‚Üê‚Üí Declension    ‚åò+‚áß+p Online   ‚Ü≤ Dictionary'"%(EXAM_ID + EXAM_PER_PAGE, start, end, len(rus)))


		def on_release(key):
			if key in [Key.esc, Key.delete]:
				system("killall dunst")
				return False

		ind, offset, play_blk, dict_flag = 0, 0, 0, 0
		current = set()
		threading.Thread(target=pronunciate).start()
		with Listener(on_press=on_press, on_release=on_release) as listener:
			listener.join()